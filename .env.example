# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
# Optional: model for topic stream only (default: OPENAI_MODEL or gpt-4o-mini); use a faster model for lower latency
# OPENAI_TOPICS_MODEL=gpt-4o-mini
# Content calendar: number of days of ideas to generate (default: 7)
# CONTENT_CALENDAR_DAYS=7

# Server Configuration
PORT=3001
NODE_ENV=development

# Database Configuration
# Use either DATABASE_URL (preferred) or individual DB parameters
DATABASE_URL=postgresql://username:password@host:port/database_name
# Alternative: Individual database parameters
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=automate_my_blog
# DB_USER=postgres
# DB_PASSWORD=your_password_here

# Authentication
JWT_SECRET=your_jwt_secret_key_here
JWT_REFRESH_SECRET=your_jwt_refresh_secret_here

# Stripe Configuration
STRIPE_SECRET_KEY=sk_test_your_stripe_secret_key_here
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret_here

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Website Analysis & Scraping
USER_AGENT="AutoBlog Bot 1.0"
ANALYSIS_TIMEOUT=10000
# Max chars of page content sent to analysis; excess truncated (default 50000)
# WEBSITE_ANALYSIS_MAX_CONTENT_CHARS=50000
# Skip web search during "Researching business context" for faster analysis (1/true/yes = skip)
# SKIP_WEBSITE_WEB_RESEARCH=1
# Cap time spent on web research in ms; 0 = no limit (e.g. 15000 = 15s)
# WEBSITE_WEB_RESEARCH_TIMEOUT_MS=15000

# Scraping (browser and fast path)
# Post-load delay in ms before content check (default 2000)
# SCRAPE_WAIT_AFTER_LOAD_MS=2000
# Timeout for waitForFunction (paragraphs/body) in ms (default 8000)
# SCRAPE_WAIT_FOR_CONTENT_TIMEOUT_MS=8000
# Fast path: HTTP request timeout in ms (default 5000); min body chars to accept (default 500)
# SCRAPE_FAST_PATH_TIMEOUT_MS=5000
# SCRAPE_FAST_PATH_MIN_CONTENT_CHARS=500

# Job Queue (Redis + BullMQ worker)
REDIS_URL=redis://localhost:6379

# YouTube Data API v3 (for video search in content workflow)
# Get key from Google Cloud Console: enable YouTube Data API v3, create credentials (API key)
YOUTUBE_API_KEY=your_youtube_api_key_here

# NewsAPI.org (for news article search in content workflow)
# Get key from https://newsapi.org - free developer tier available (localhost only for free)
NEWS_API_KEY=your_news_api_key_here

# Super Admin Configuration
# Comma-separated list of email addresses that will be automatically promoted to super_admin role
# These users will have full platform access including user management, analytics, and system settings
SUPER_ADMIN_EMAILS=admin@yourdomain.com

# Admin panel (stats + cache): optional API key for server-to-server or browser access without login
# When set, allow access via header x-admin-key or query admin_key (e.g. /admin?admin_key=xxx)
# ADMIN_API_KEY=your_secret_admin_key_here

# Google API Integrations
# Google Trends API key (if using official API; alternatively use google-trends-api npm package)
GOOGLE_TRENDS_API_KEY=

# Google Search Console - Service account credentials JSON
# Get from Google Cloud Console > APIs & Services > Credentials
# Create Service Account, download JSON key, paste entire JSON here (or use GOOGLE_CLIENT_ID/SECRET for OAuth)
GOOGLE_SEARCH_CONSOLE_CREDENTIALS=

# Google Search Console - Property ID (e.g., sc-domain:example.com or https://example.com/)
GOOGLE_SEARCH_CONSOLE_PROPERTY_ID=

# Google Analytics 4 - Service account credentials JSON
# Get from Google Cloud Console > APIs & Services > Credentials
# Create Service Account with Analytics Viewer role, download JSON key, paste entire JSON here
GOOGLE_ANALYTICS_CREDENTIALS=

# Google Analytics 4 - Property ID (numeric ID from GA4 admin panel)
GOOGLE_ANALYTICS_PROPERTY_ID=

# OAuth 2.0 Client Credentials (for user-authenticated Google API access)
# Get from Google Cloud Console > APIs & Services > Credentials > OAuth 2.0 Client IDs
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
GOOGLE_REDIRECT_URI=http://localhost:3001/api/v1/auth/google/callback